{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad11a68d-e6e3-4204-a016-5ab710ec1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aead944-a1b0-492f-a601-7e75ea71009c",
   "metadata": {},
   "source": [
    "# Step 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36296b25-dd58-40d2-aaca-55b45dc06757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'product', 'narrative'], dtype='object')\n",
      "(162421, 3)\n",
      "   Unnamed: 0           product  \\\n",
      "0           0       credit_card   \n",
      "1           1       credit_card   \n",
      "2           2    retail_banking   \n",
      "3           3  credit_reporting   \n",
      "4           4  credit_reporting   \n",
      "\n",
      "                                           narrative  \n",
      "0  purchase order day shipping amount receive pro...  \n",
      "1  forwarded message date tue subject please inve...  \n",
      "2  forwarded message cc sent friday pdt subject f...  \n",
      "3  payment history missing credit report speciali...  \n",
      "4  payment history missing credit report made mis...  \n",
      "\n",
      "Category Distribution:\n",
      "category\n",
      "credit_reporting       91172\n",
      "debt_collection        23148\n",
      "mortgages_and_loans    18990\n",
      "credit_card            15566\n",
      "retail_banking         13535\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('complaints.csv')\n",
    "\n",
    "# Let's see the columns, shape, and first few rows\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "df = df[['product', 'narrative']].copy()\n",
    "df.dropna(inplace=True) # Remove rows with missing values\n",
    "df.rename(columns={'product': 'category', 'narrative': 'text'}, inplace=True)\n",
    "\n",
    "# Check the distribution of categories\n",
    "print(\"\\nCategory Distribution:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ff19d-664f-4c7a-98fb-f1527bbd261d",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c52b6d1-d786-4cfe-b8e6-23c8d57eb7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text... this may take a moment.\n",
      "Preprocessing complete.\n",
      "                                                text  \\\n",
      "0  purchase order day shipping amount receive pro...   \n",
      "1  forwarded message date tue subject please inve...   \n",
      "2  forwarded message cc sent friday pdt subject f...   \n",
      "3  payment history missing credit report speciali...   \n",
      "4  payment history missing credit report made mis...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  purchase order day shipping amount receive pro...  \n",
      "1  forwarded message date tue subject please inve...  \n",
      "2  forwarded message cc sent friday pdt subject f...  \n",
      "3  payment history missing credit report speciali...  \n",
      "4  payment history missing credit report made mis...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # 2. Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 3. Tokenize and remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # 4. Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to our text column\n",
    "print(\"Preprocessing text... this may take a moment.\")\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"Preprocessing complete.\")\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d2b68-064f-4359-b1d2-d989f3c6db0d",
   "metadata": {},
   "source": [
    "# Step 3: Feature Extraction (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc93794-0401-4d9d-a653-746185448249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF training data: (129928, 5000)\n",
      "Shape of TF-IDF testing data: (32483, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df['cleaned_text']\n",
    "y = df['category']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "# This is crucial to evaluate the model on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "# We'll limit to the top 5000 most frequent words to keep the feature set manageable\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on the training data and transform it\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only transform the test data using the already fitted vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Shape of TF-IDF training data: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape of TF-IDF testing data: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714f0c4-5d8c-4524-8492-a7dea580ba71",
   "metadata": {},
   "source": [
    "# Step 4: Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d14645-4d24-4cc1-8ad1-4a2a3318dc1e",
   "metadata": {},
   "source": [
    "# a. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51421192-9248-4f22-8b3d-c3c8c8008f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multinomial Naive Bayes model...\n",
      "Training Linear SVM model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Model 1: Multinomial Naive Bayes ---\n",
    "print(\"Training Multinomial Naive Bayes model...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# --- Model 2: Linear SVM ---\n",
    "print(\"Training Linear SVM model...\")\n",
    "svm_model = LinearSVC(random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620bcb1-cb72-4d8f-a57b-c1a5cfa721ab",
   "metadata": {},
   "source": [
    "# b. Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaa4c83f-51f4-41be-a183-bf080dcaf429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multinomial Naive Bayes Evaluation ---\n",
      "Accuracy: 0.8378\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        credit_card       0.73      0.73      0.73      3113\n",
      "   credit_reporting       0.88      0.91      0.89     18235\n",
      "    debt_collection       0.82      0.60      0.69      4630\n",
      "mortgages_and_loans       0.76      0.85      0.80      3798\n",
      "     retail_banking       0.84      0.84      0.84      2707\n",
      "\n",
      "           accuracy                           0.84     32483\n",
      "          macro avg       0.80      0.79      0.79     32483\n",
      "       weighted avg       0.84      0.84      0.83     32483\n",
      "\n",
      "\n",
      "--- Linear SVM Evaluation ---\n",
      "Accuracy: 0.8720\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        credit_card       0.79      0.77      0.78      3113\n",
      "   credit_reporting       0.91      0.94      0.92     18235\n",
      "    debt_collection       0.81      0.73      0.77      4630\n",
      "mortgages_and_loans       0.85      0.82      0.84      3798\n",
      "     retail_banking       0.86      0.87      0.87      2707\n",
      "\n",
      "           accuracy                           0.87     32483\n",
      "          macro avg       0.84      0.83      0.83     32483\n",
      "       weighted avg       0.87      0.87      0.87     32483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Naive Bayes\n",
    "print(\"\\n--- Multinomial Naive Bayes Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Evaluate Linear SVM\n",
    "print(\"\\n--- Linear SVM Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902766ca-3470-4bcb-aa77-137ecb641526",
   "metadata": {},
   "source": [
    "# Save the Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52acddb6-2a7f-43dc-aba3-a887f0605709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Choose the best model (e.g., SVM) and retrain on ALL data\n",
    "final_model = LinearSVC(random_state=42)\n",
    "final_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit on the entire dataset\n",
    "X_tfidf_full = final_vectorizer.fit_transform(X)\n",
    "final_model.fit(X_tfidf_full, y)\n",
    "\n",
    "# Save the artifacts\n",
    "joblib.dump(final_model, 'ticket_classifier_model.joblib')\n",
    "joblib.dump(final_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "print(\"Model and vectorizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dab3cb-49d6-47b2-82fb-dc461acee83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
