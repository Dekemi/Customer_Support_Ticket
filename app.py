# -*- coding: utf-8 -*-
"""app-Customer_Support_Ticket

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16OuaWP2gLG6t-OfvOo1EhcuusF4mgrVU
"""

# app.py

from flask import Flask, request, jsonify
import joblib
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Ensure NLTK resources are available

for resource in ("stopwords", "wordnet"):
    try:
        nltk.data.find(f"corpora/{resource}")
    except LookupError:
        nltk.download(resource)

# Initialize Flask app
app = Flask(__name__)

# Load the trained model and vectorizer
model = joblib.load("ticket_classifier_model.joblib")
vectorizer = joblib.load("tfidf_vectorizer.joblib")

# Preprocessing setup
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words("english"))

def preprocess_text(text: str) -> str:
    """Clean and preprocess text exactly as during training."""
    text = text.lower()
    text = re.sub(r"[^a-z\s]", "", text)
    words = text.split()
    words = [word for word in words if word not in stop_words]
    words = [lemmatizer.lemmatize(word) for word in words]
    return " ".join(words)

# Prediction endpoint

@app.route("/predict", methods=["POST"])
def predict():
    data = request.get_json(force=True)

    subject = data.get("subject", "")
    description = data.get("description", "")

    if not subject and not description:
        return jsonify({"error": "No subject or description provided"}), 400

    text = subject + " " + description

    cleaned_text = preprocess_text(text)
    text_vector = vectorizer.transform([cleaned_text])
    prediction = model.predict(text_vector)

    return jsonify({"predicted_category": prediction[0]})

# Run the app

if __name__ == "__main__":
    # Use gunicorn for production; Flask dev server is for testing
    app.run(debug=True, port=5000)
